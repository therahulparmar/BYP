# -*- coding: utf-8 -*-
"""Copy of Copy of Copy of Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d1lnu4PGb32xEBLcZGRJMBZ0VytuZZsF
"""

# Import required libraries
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import sklearn

# Import necessary modules
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt

# Keras specific
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical 
df = pd.read_csv("data.csv")

print(df.shape)

# X = dataset.iloc[:,16:17].values
# y = dataset.iloc[:,14].values

target_column = ['fruitset'] 

predictors = ['seeds']
df[predictors] = df[predictors]/df[predictors].max()

X = df[predictors].values
y = df[target_column].values

# print(y)
x1 = []
y1 = []
idx = 0
y = [int(np.round(i,1)*10) for i in y]
for i in range(0,777):
  if y[i] != 7:
    x1.append(X[i])
    y1.append(y[i])
  else:
    idx = i
print(set(y1))

X_train, X_test, y_train, y_test = train_test_split(x1, y1, test_size=0.30, random_state=40)
X_train= np.array(X_train)
y_train = np.array(y_train)
X_test= np.array(X_test)
y_test = np.array(y_test)
print(y_test)

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print(y_test)
count_classes = y_test.shape[1]
print(count_classes)

model = Sequential()
model.add(Dense(64, activation='relu', input_dim=1))
model.add(Dense(32, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(count_classes, activation='softmax'))

model.compile(optimizer='adam', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

# X_train= np.array(X_train)
# y_train = np.array(y_train)
# X_test= np.array(X_test)
# y_test = np.array(y_test)

model.fit(X_train, y_train, epochs=10, batch_size=1)

pred_train= model.predict(X_train)
scores = model.evaluate(X_train, y_train, verbose=0)
print('Accuracy on training data: {}% \n Error on training data: {}'.format(scores[1], 1 - scores[1]))   
 
pred_test= model.predict(X_test)
scores2 = model.evaluate(X_test, y_test, verbose=0)
print('Accuracy on test data: {}% \n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))

# predicted_val = model.predict(seed_val) 
# seed  ==?(model) pred_fruitset(model2)  => trniaed_yield
# fruitset(model2) == > yield
# print(len(x1))
x5 = []
# for i in range(0,777):
#   if i != idx:
#     x5.append(x1[i])
x5 = np.array(x1)
# print(len(x5))
trained_actions = model.predict(x5)  # 776 x 7
print()
t2 = np.argmax(trained_actions, axis=1)
# # print(np.argmax(trained_actions[0]))
# x2 = []
# for i in range(0,776):
#   # x1[i] = [np.float32(j) for j in x1[i]]
#   # print(type(x1[i][0]))
#   x6 = np.append(x5[i],t2[i]/10)
#   x2.append(x6)
# # x4 = np.append(x1, trained_actions, axis = 1)
# # # for i in range(0,776):
# # #   x1 = np.append()
# print(x2)
target_column = 'yield'
# df[target_column] = df[target_column]/df[target_column].max()
y2 =  df[target_column].values
y2 = [(i - np.min(y2))/(np.max(y2) - np.min(y2)) for i in y2]
y3 = []
# print(idx)
for i in range(0,777):
  if i != idx:
    y3.append(y2[i])
# print(len(y3))

X_train1, X_test1, y_train1, y_test1 = train_test_split(t2, y3, test_size=0.30, random_state=40)
X_train1= np.array(X_train1)
y_train1 = np.array(y_train1)
X_test1= np.array(X_test1)
y_test1 = np.array(y_test1)
print(set(y_test1))
print(set(y_train1))

# y_train1 = to_categorical(y_train1)
# y_test1 = to_categorical(y_test1)

# count_classes = y_test1.shape[1]
# print(count_classes)

model2 = Sequential()
model2.add(Dense(64, activation='relu', input_dim=1))
model2.add(Dense(128, activation='relu'))
model2.add(Dense(64, activation='relu'))
# model2.add(Dense(32, activation='relu', input_dim=1))
# model2.add(Dense(16, activation='relu', input_dim=1))
model2.add(Dense(1,activation='linear'))

import keras
import keras.backend as kb
# import tensorflow as tf

# optimizer = Adam(lr=1e-3)

from keras import backend as K

def soft_acc(y_true, y_pred):
    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))

model2.compile(optimizer='adam', loss='mae',metrics=[soft_acc])

model2.fit(X_train1, y_train1, epochs=10, batch_size=1)

score = model2.evaluate(X_test1, y_test1, batch_size=32)
# pred_train= model2.predict(X_train1)
# scores = model2.evaluate(X_train1, y_train1, verbose=0)
# print('mae on training data: {}%'.format(scores[1]))   
 
# pred_test= model2.predict(X_test1)
# scores2 = model2.evaluate(X_test1, y_test1, verbose=0)
# print('mae on test data: {}%'.format(scores2[1]))   

# value_y = model2.predict(value_x)

import random
# p = []
# for i in range(0,776):
#   p.append(random.randint(2,6)
x7 = []
for i in range(0,776):
  x7.append(random.randint(2,6))
# print(len(x3),len(y2))

X_train2, X_test2, y_train2, y_test2 = train_test_split(x7, y3, test_size=0.30, random_state=40)
X_train2= np.array(X_train2)
y_train2 = np.array(y_train2)
X_test2= np.array(X_test2)
y_test2 = np.array(y_test2)
print(set(y_test2))
print(set(y_train2))

# y_train2 = to_categorical(y_train2)
# y_test2 = to_categorical(y_test2)

# count_classes = y_test2.shape[1]
# print(count_classes)

model3 = Sequential()
model3.add(Dense(64, activation='relu', input_dim=1))
model3.add(Dense(128, activation='relu'))
model3.add(Dense(64, activation='relu'))
# model2.add(Dense(32, activation='relu', input_dim=1))
# model2.add(Dense(16, activation='relu', input_dim=1))
model3.add(Dense(32,activation='linear'))

import keras
import keras.backend as kb
# import tensorflow as tf

# optimizer = Adam(lr=1e-3)
model3.compile(optimizer='adam', 
              loss='mae',metrics=[soft_acc])

"""Here we found this: https://stackoverflow.com/questions/45632549/why-is-the-accuracy-for-my-keras-model-always-0-when-training"""

model3.fit(X_train2, y_train2, epochs=10, batch_size=1)

score = model3.evaluate(X_test2, y_test2, batch_size=32)
# pred_train= model3.predict(X_train2)
# scores = model3.evaluate(X_train2, y_train2, verbose=0)
# print('mae on training data: {}%'.format(scores[1]))   
 
# pred_test= model3.predict(X_test2)
# scores2 = model3.evaluate(X_test2, y_test2, verbose=0)
# print('mae on test data: {}%'.format(scores2[1]))

model.save("model1")
model2.save("model2")

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_X = scaler.fit_transform(X)

import pickle

pickle.dump(scaler, open('scaler.pkl', 'wb'))




# print(type(model2))

# p1 = np.array([0.3])
# p2 = np.array([5])
# yyy = model.predict(p1)


# yyy = np.argmax(yyy,axis=1)
# print(yyy)

# yyyy = model2.predict(yyy)
# print(yyyy)

# y_predicted = model2.predict(p2)

# print(y_predicted)

from keras.models import load_model

# model_load = load_model('model2.h5', custom_objects={'soft_acc' : soft_acc })
# model_load.summary()


# from deepctr.layers import custom_objects

# custom_objects["soft_acc"] = soft_acc



model = load_model('model2', custom_objects={'soft_acc':soft_acc})

model.summary()


#  [[0.22]]
#   [2323]